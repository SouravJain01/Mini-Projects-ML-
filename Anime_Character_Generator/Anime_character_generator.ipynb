{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkn4dIXbaG8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1JePRMdaKy3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd \"./drive/My Drive/data\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO2E3aUufBCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQxjX54EoGdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P1qsQQ7DBn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_default_tensor_type('torch.DoubleTensor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEySHPh7a-Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_from_dataset(batch_size,img_shape,data_dir=None):\n",
        "  sample=[]\n",
        "  global_data_dir=list(glob.glob(data_dir))\n",
        "  sample_img_path=np.random.choice(global_data_dir,batch_size)\n",
        "  for index,img_filename in enumerate(sample_img_path):\n",
        "    img=Image.open(img_filename)\n",
        "    img=img.resize(img_shape[:-1])\n",
        "    #img=img.convert('RGB')\n",
        "    img=np.asarray(img)\n",
        "    img=(img/127.5)-1\n",
        "    sample.append(img)\n",
        "  return torch.from_numpy(np.asarray(sample))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1WdYmq5fE3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weights_init(m):\n",
        "  classname=m.__class__.__name__\n",
        "  if classname.find('Conv')!=-1:\n",
        "    m.weight.data.normal_(0.0,0.02)\n",
        "  elif classname.find('BatchNorm')!=-1:\n",
        "    m.weight.data.normal_(1.0,0.02)\n",
        "    m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf2sW9AGhxwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class G(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(G,self).__init__()\n",
        "    self.main=nn.Sequential(\n",
        "        nn.ConvTranspose2d(100,512,4,1,0,bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(512,256,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(256,128,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(128,64,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(True),\n",
        "        nn.ConvTranspose2d(64,3,4,2,1,bias=False),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "  def forward(self,input):\n",
        "    output=self.main(input)\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5UE53uCkSv_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netG=G()\n",
        "netG.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEq6OJDAkZwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class D(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(D,self).__init__()\n",
        "    self.main=nn.Sequential(\n",
        "        nn.Conv2d(3,64,4,2,1,bias=False),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Conv2d(64,128,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Conv2d(128,256,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Conv2d(256,512,4,2,1,bias=False),\n",
        "        nn.BatchNorm2d(512),\n",
        "        nn.LeakyReLU(0.2,inplace=True),\n",
        "        nn.Conv2d(512,1,4,1,0,bias=False),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self,input):\n",
        "    output=self.main(input)\n",
        "    return output.view(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_rZvlznmB7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "netD=D()  \n",
        "netD.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMvpuwzomLKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion=nn.BCELoss()\n",
        "optimizerD=optim.Adam(netD.parameters(),lr=0.00015,betas=(0.5,0.999))\n",
        "optimizerG=optim.Adam(netG.parameters(),lr=0.00015,betas=(0.5,0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X15yE5UTmoKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(10000):\n",
        "  #updating the weights of the neural network of discriminator\n",
        "  netD.zero_grad()\n",
        "  #training discriminator with real image dataset\n",
        "  data=sample_from_dataset(64,(64,64,64),data_dir=\"content/drive/My Drive/data/*.png\")\n",
        "  data=data.permute(0,3,1,2)\n",
        "  input=Variable(data)\n",
        "  target=Variable(torch.ones(input.size()[0]))\n",
        "  output=netD(input)\n",
        "  errD_real=criterion(output,target)\n",
        "  #training discriminator with fake image generated by generator\n",
        "  noise=Variable(torch.randn(input.size()[0],100,1,1))\n",
        "  fake=netG(noise)\n",
        "  target=Variable(torch.zeros(input.size()[0]))\n",
        "  output=netD(fake.detach())\n",
        "  errD_fake=criterion(output,target)\n",
        "  #Backpropagating the total error\n",
        "  errD=errD_real + errD_fake\n",
        "  errD.backward()\n",
        "  optimizerD.step()\n",
        "  #updating the weights of the neural network of generator\n",
        "  netG.zero_grad()\n",
        "  target=Variable(torch.ones(input.size()[0]))\n",
        "  output=netD(fake)\n",
        "  errG=criterion(output,target)\n",
        "  errG.backward()\n",
        "  optimizerG.step()\n",
        "  if epoch%100==0:\n",
        "    print('%d epochs done' % epoch)\n",
        "  if epoch%200==0:\n",
        "    print('[%d/%d]Loss_D: %.4f Loss_G: %.4f' % (epoch,8000,errD.data,errG.data))\n",
        "  if epoch%1000==0:\n",
        "    torch.save(netG.state_dict(),\"./content/drive/My Drive/results/GENERATOR_%03d.pth\" % epoch)\n",
        "    torch.save(netD.state_dict(),\"./content/drive/My Drive/results/DISCRIMINATOR_%03d.pth\" % epoch)\n",
        "  if epoch%500==0:\n",
        "    vutils.save_image(data,'%s/real_samples.png' % \"./content/drive/My Drive/results\",normalize=True)\n",
        "    fake=netG(noise)\n",
        "    vutils.save_image(fake.data,'%s/reFake_samples_epoch_%03d.png' % (\"./content/drive/My Drive/results\",epoch),normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRGtNjhDq1i8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=G()\n",
        "model.apply(weights_init)\n",
        "model.load_state_dict(torch.load(\"./drive/My Drive/results/reGENERATOR_3000.pth\"))\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciprXS3TtCoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise=Variable(torch.randn(64,100,1,1))\n",
        "fake=model(noise)\n",
        "fake.data\n",
        "vutils.save_image(fake.data,'%s/Check.png' % (\"./drive/My Drive/results\"),normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}